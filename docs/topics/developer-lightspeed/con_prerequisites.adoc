:_newdoc-version: 2.15.0
:_template-generated: 2024-2-21

:_mod-docs-content-type: CONCEPT

[id="prerequisites_{context}"]
= Prerequisites

[role="_abstract"]
Before you install {mta-dl-plugin}, you must:

* Install Language Support for Java(TM) by Red Hat extension

* Install Java v17 and later

* Install Maven v3.9.9 or later

* Install Git and add it to the $PATH variable

* Install the {ProductShortName} Operator 8.0.0
+

The {ProductShortName} Operator is mandatory if you plan to enable the solution server that works with the large language model (LLM) for generating code changes. It enables you to log in to the `openshift-mta` project where you must enable the Solution Server in the Tackle custom resources (CR).

* Create an API key for an LLM.
+

You must enter the provider value and model name in Tackle custom resource (CR) to enable generative AI configuration in the {ProductShortName} VS Code plugin. 
+
.Configurable large language models and providers
|===
| LLM Provider (Tackle CR value) | Large language model examples for Tackle CR configuration

| {ocp-name} AI platform| Models deployed in an {ocp-name} AI cluster that can be accessed by using Open AI-compatible API.
| Open AI (`openai`) | `gpt-4`, `gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo` 
| Azure OpenAI (`azure_openai`) | `gpt-4`, `gpt-35-turbo` 
| Amazon Bedrock (`bedrock`) | `anthropic.claude-3-5-sonnet-20241022-v2:0`, `meta.llama3-1-70b-instruct-v1:0` 
| Google Gemini (`google`) | `gemini-2.0-flash-exp`, `gemini-1.5-pro` 
| Ollama (`ollama`) | `llama3.1`, `codellama`, `mistral` 

|===

[NOTE]
====
The availability of public LLM models is maintained by the respective LLM provider.
====