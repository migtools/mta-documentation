:_newdoc-version: 2.18.3
:_template-generated: 2025-02-26
:_mod-docs-content-type: PROCEDURE

[id="configuring-developer-lightspeed-ide-settings_{context}"]
= Configuring the {mta-dl-plugin} IDE settings

After you install the {ProductShortName} extension in Visual Studio (VS) Code, you must provide your large language model (LLM) credentials to activate {mta-dl-plugin} settings in Visual Studio (VS) Code. 

{mta-dl-plugin} settings are applied to all AI-assisted analysis that you perform by using the {ProductShortName} extension. The extension settings can be broadly categorized into debugging and logging, {mta-dl-plugin} settings, analysis related settings, and solution server settings.

.Prerequisites

* You installed the {ProductFullName} extension version 8.0.0 in VS Code. 
* You completed the solution server configurations in Tackle custom resource if you opt to use solution server.
* You installed the {ProductShortName} version 8.0.0 in your system. 
* You installed the latest version of Language Support for Java(TM) by Red Hat extension in VS Code.
* You installed Jave 17+ and Maven 3.9.9+ in your system. 
* You installed Git and add it to the $PATH variable.


.Procedure

. Go to the {mta-dl-plugin} settings in one of the following ways:
+
.. Click `Extensions > MTA CLI Extension for VSCode > Settings`
+
.. Type `Ctrl + Shift + P` on the search bar to open the Command Palette and enter `Preferences: Open Settings (UI)`. Go to `Extensions > MTA` to open the settings page.
+
. Configure the settings described in the following table:

.{mta-dl-plugin}  settings
[cols="40%,60%a",options="header",]
|====
|Settings |Description
|Log level|Set the log level for the {ProductShortName} binary. The default log level is `debug`. The log level increases or decreases the verbosity of logs. 
|RPC Server Path|Displays the path to the solution server binary. If you do not modify the path, {mta-dl-plugin} uses the bundled binary.
|Analyzer path|Specify a {ProductShortName} custom binary path. If you do not provide a path, {mta-dl-plugin} uses the default path to the binary.
|Solution Server:URL|Configure the URL of the Solution Server end point. This field has the default URL.
|Solution Server:enabled|Enable the Solution Server client ({ProductShortName} extension) to connect to the Solution Server to perform analysis.
|Solution Server:Auth| Enable authentication for the Solution Server. 
|Solution Server:Auth Realm| Enter the name of the Keycloak realm for Solution Server. 

If you enabled authentication for the Solution Server, you must configure a link:https://docs.redhat.com/en/documentation/red_hat_build_of_keycloak/26.0/html/server_administration_guide/red_hat_build_of_keycloak_features_and_concepts[Keycloak realm] to allow clients to connect to the Solution Server. An administrator can configure SSL for the realm.
|Solution Server: Auth Insecure|This option is enabled by default to skip SSL certificate verification when clients connect to the Solution Server. Disable the setting to allow secure connections to the Solution Server.
|Analyze on save|Enable this setting for {mta-dl-plugin} to run an analysis on a file that is saved after code modification. This setting is enabled automatically when you enable Agentic AI mode.
|Diff editor type|Select from diff or merge view to review the suggested solutions after running an analysis. The diff view shows the old code and a copy of the code with changes side-by-side. The merge view overlays the changes in the code in a single view.
|Gen AI:Enabled|This option is enabled by default. It enables you to get code fixes by using {mta-dl-plugin} with a large language model.
|Diff:Auto Accept On Save|This option is enabled by default. When you accept the changes suggested by the LLM, the updated code is saved automatically in a new file. Disable this option if you want to manually save the new file after accepting the suggested code changes.
|Agent mode|Enable the experimental Agentic AI flow for analysis. {mta-dl-plugin} runs an automated analysis of a file to identify issues and suggest resolutions. After you accept the solutions, {mta-dl-plugin} makes the changes in the code and re-analyzes the file. 
|Excluded diagnostic sources|Add diagnostic sources in the `settings.json` file. The issues generated by such diagnostic sources are excluded from the automated Agentic AI analysis. 
|Cache directory|Specify the path to a directory in your filesystem to store cached responses from the LLM. 
|Demo mode|Enable to run {mta-dl-plugin} in demo mode that uses the LLM responses saved in the `cache` directory for analysis. 
|Trace enabled|Enable to trace {ProductShortName} communication with the LLM model. Traces are stored in the `/.vscode/konveyor-logs/traces` path in your IDE project.
|Debug:Webview|Enable debug level logging for Webview message handling in VS Code. 
|Analyze dependencies|Enable {mta-dl-plugin} to analyze dependency-related errors detected by the LLM in your project.
|Analyze known libraries|Enable {mta-dl-plugin} to analyze well-known open-source libraries in your code.
|Code snip limit|Set the maximum number of lines of code that are included in incident reports.
|Context lines|Configure the number of context lines included in incident reports. The greater the number, the more the LLM accuracy.
|Incident limit|Specifies the maximum number of incidents to be reported. If you enter a higher value, it increases the coverage of incidents in your report.
|====

