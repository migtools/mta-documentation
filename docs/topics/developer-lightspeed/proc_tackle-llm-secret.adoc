:_newdoc-version: 2.15.0
:_template-generated: 2024-2-21
:_mod-docs-content-type: PROCEDURE

[id="tackle-llm-secret_{context}"]
= Configuring the model secret key

[role="_abstract"]

You must configure the Kubernetes secret for the large language model (LLM) provider in the {ocp-short} project where you installed the {ProductShortName} operator. 

.Procedure

. Create a credentials secret named `kai-api-keys` in the `openshift-mta` project.
.. For the default IBM GenAI provider `ChatIBMGenAI`, type:
+
[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
--from-literal=genai_key='<YOUR_IBM_GENAI_KEY>'
----
+
.. For the Google as the provider, type:
+
[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
 --from-literal=google_key='<YOUR_GOOGLE_API_KEY>'
----
+
.. For the OpenAI-compatible providers, type:
+
[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
 --from-literal=api_base='https://api.openai.com/v1' \
 --from-literal=api_key='<YOUR_OPENAI_KEY>'
----
+
. (Optional) Force a reconcile so that the {ProductShortName} operator picks up the secret immediately
+
//Is the double tackle needed in the command?
[source, terminal]
----
kubectl patch tackle tackle -n openshift-mta --type=merge -p \
'{"metadata":{"annotations":{"konveyor.io/force-reconcile":"'"$(date +%s)"'"}}}'
----