:_newdoc-version: 2.15.0
:_template-generated: 2024-2-21
:_mod-docs-content-type: PROCEDURE

[id="tackle-llm-secret_{context}"]
= Configuring the model secret key

[role="_abstract"]
You must configure the Kubernetes secret for the large language model (LLM) provider in the {ocp-short} project where you installed the {ProductShortName} operator. 

.Procedure

. Create a credentials secret named `kai-api-keys` in the `openshift-mta` project.

.. For Amazon Bedrock as the provider, type:
+
[source, terminal]
----
kubectl create secret generic aws-credentials \
 --from-literal=AWS_ACCESS_KEY_ID=<YOUR_AWS_ACCESS_KEY_ID> \
 --from-literal=AWS_SECRET_ACCESS_KEY=<YOUR_AWS_SECRET_ACCESS_KEY>
----
+

.. For Azure OpenAI as the provider, type:
+
[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
 --from-literal=AZURE_OPENAI_API_KEY='<YOUR_AZURE_OPENAI_API_KEY>'
----
+

.. For the Google as the provider, type:
+
[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
 --from-literal=GEMINI_API_KEY='<YOUR_GOOGLE_API_KEY>'
----
+

.. For the OpenAI-compatible providers, type:
+

[source, terminal]
----
kubectl create secret generic kai-api-keys -n openshift-mta \
 --from-literal=OPENAI_API_BASE='https://example.openai.com/v1' \
 --from-literal=OPENAI_API_KEY='<YOUR_OPENAI_KEY>'
----
+
[NOTE]
====
You can also set the base URL as the `kai_llm_baseurl` variable in the Tackle custom resource.
====
+

. (Optional) Force a reconcile so that the {ProductShortName} operator picks up the secret immediately
+

[source, terminal]
----
kubectl patch tackle tackle -n openshift-mta --type=merge -p \
'{"metadata":{"annotations":{"konveyor.io/force-reconcile":"'"$(date +%s)"'"}}}'
----
//Is the double tackle needed in the command?