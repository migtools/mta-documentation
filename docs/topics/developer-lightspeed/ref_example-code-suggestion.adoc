:_newdoc-version: 2.15.0
:_template-generated: 2024-2-21
:_mod-docs-content-type: REFERENCE

[id="example-code-generation_{context}"]
= Generating code fix suggestions example

[role="_abstract"]
This example will walk you through generating code fixes for a Java application that must be migrated to `quarkus`. To generate resolutions for issues in the code, we use the Agentic AI mode and the `my-model` as the large language model (LLM) that you deployed in {ocp-name} AI.

.Procedure

. Open the `my-Java` project in Visual Studio (VS) Code.

. Download the {mta-dl-full} extension from the link:https://marketplace.visualstudio.com/search?term=migration%20toolkit&target=VSCode&category=All%20categories&sortBy=Relevance[VS Code marketplace].

. Open Command Palette:

.. Type `Ctrl+Shift+P` in Windows and Linux systems.
.. Type `Cmd+Shift+P` in Mac systems.

. Type `Preferences: Open Settings (UI)` in the Command Palette to open the VS Code settings and select `Extensions > {ProductShortName}`.

. Select `Gen AI:Agent Mode`.

. In the {mta-dl-plugin} extension, click `Open Analysis View`.

. Type `MTA: Manage Analysis Profile` in the Command Palette to open the analysis profile page.

. Configure the following fields:

.. *Profile Name*: Type a profile name

.. *Target Technologies*: `quarkus`

.. *Custom Rules*: Select custom rules if you want to include them while running the analysis. By default, {mta-dl-plugin} enables *Use Default Rules* for `quarkus`.

. Close the profile manager.

. Type `MTA: Open the Gen AI model provider configuration file` in the Command Palette.

. Configure the following in the `provider-settings` file and close it:
+
[source, yaml]
----
models:
  openshift-example-model: &active
    environment:
      OPENAI_API_KEY: "<Server's OPENAI_API_KEY>"
      CA_BUNDLE: "<Servers CA Bundle path>"
    provider: "ChatOpenAI"
    args:
      model: "my-model"
      configuration:
        baseURL: "https://<serving-name>-<data-science-project-name>.apps.konveyor-ai.migration.redhat.com/v1"
----
+
[NOTE]
====
You must change the `provider-setting` configuration if you plan to use a different LLM provider.
====

. Type `{ProductShortName}: Open Analysis View` in the Command Palette.

. Click *Start* to start the {mta-dl-plugin} server.
+
Starting the server activates the *Run Analysis* feature.

. Select the profile you configured. 

. Click *Run Analysis* to scan the Java application.
+
{ProductShortName} identifies the issues in the code.

. Click the solutions icon in an issue to request suggestions to resolve the issue.
+
{mta-dl-plugin} streams the issue description, code change that resolves the issue, and the file in which the changes are to be made.
+
You can review the code changes in a diff editor and accept or reject the changes. If you accept the changes, {mta-dl-plugin} creates a new file with the accepted code changes.
+
. Click *Continue* to allow {mta-dl-plugin} to run a follow-up analysis. 
+
This round of analysis detects lint issues, compilation issues, or diagnostic issues that may have occurred when you accepted the suggested code change.
+
Repeat the review and accept or reject the resolutions. {mta-dl-plugin} continues to run repeated rounds of scan if you allow until all issues are resolved. 